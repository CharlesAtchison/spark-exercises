{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f083b29-fe4e-42c8-8232-e10af88b4db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/11/09 08:24:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from datetime import datetime \n",
    "\n",
    "# Import pandas to help with readability of answers\n",
    "import pandas as pd\n",
    "\n",
    "# Build pyspark session and turn off warnings\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df6bf5ef-ef79-436c-8757-dfd0786ac28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "  table {margin-left: 0 !important;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "  table {margin-left: 0 !important;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c80593c-774c-43a5-9698-e4140eefcd4c",
   "metadata": {},
   "source": [
    "## This exercise uses the `case.csv`, `dept.csv`, and `source.csv` files from the san antonio 311 call dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b90e0f4-a070-4d31-aafe-709354207ab3",
   "metadata": {},
   "source": [
    "### 1.Read the case, department, and source data into their own spark dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d69453ab-c522-4f77-98fc-c64a0e4c3089",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# import the csv files\n",
    "case = spark.read.csv('case.csv', sep=\",\", header=True, inferSchema=True)\n",
    "dept = spark.read.csv('dept.csv', sep=\",\", header=True, inferSchema=True)\n",
    "source = spark.read.csv('source.csv', sep=\",\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c87aaa8-cbe0-404e-bc16-acec8bcdf41c",
   "metadata": {},
   "source": [
    "### 2. Let's see how writing to the local disk works in spark:\n",
    "> * Write the code necessary to store the source data in both csv and json format, store these as `sources_csv` and `sources_json`\n",
    "> * Inspect your folder structure. What do you notice?\n",
    "    * I notice that the files are stored within a directory and not in a typical json or csv format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e28148d-4133-437a-8e7f-ab6338b2f525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data as sources_csv.csv and ignore if the file already exists\n",
    "source.write.csv('sources_csv.csv', mode='ignore')\n",
    "source.write.json('sources_json.json', mode='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3b6f2b-5ae2-4e56-921e-e59e77825d0e",
   "metadata": {},
   "source": [
    "### 3. Inspect the data in your dataframes. Are the data types appropriate? Write the code necessary to cast the values to the appropriate types.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e1cbeed-5c38-4b61-8a6b-427c69658920",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------------------------------------\n",
      " case_id              | 1014127332                           \n",
      " case_opened_date     | 2018-01-01 00:42:00                  \n",
      " case_closed_date     | 2018-01-01 12:29:00                  \n",
      " SLA_due_date         | 2020-09-26 00:42:00                  \n",
      " case_late            | false                                \n",
      " num_days_late        | 998                                  \n",
      " case_closed          | true                                 \n",
      " dept_division        | Field Operations                     \n",
      " service_request_type | Stray Animal                         \n",
      " SLA_days             | 999                                  \n",
      " source_id            | svcCRMLS                             \n",
      " request_address      | 2315  EL PASO ST, San Antonio, 78207 \n",
      " council_district     | 5                                    \n",
      "only showing top 1 row\n",
      "\n",
      "-RECORD 0----------------------------------\n",
      " dept_division          | 311 Call Center  \n",
      " dept_name              | Customer Service \n",
      " standardized_dept_name | Customer Service \n",
      " dept_subject_to_SLA    | true             \n",
      "only showing top 1 row\n",
      "\n",
      "-RECORD 0---------------------------\n",
      " source_id       | 100137           \n",
      " source_username | Merlene Blodgett \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dates will need to be formatted, creating a UDF will be an option to do this\n",
    "date_convert_udf = udf(lambda date: datetime.strptime(date, \"%m/%d/%y %H:%M\"), TimestampType())\n",
    "\n",
    "# Case csv file datatype conversions \n",
    "case = (\n",
    "    case.\n",
    "    withColumn('case_opened_date',\n",
    "               date_convert_udf(col('case_opened_date'))).\n",
    "    withColumn('case_closed_date',\n",
    "               date_convert_udf(col('case_closed_date'))).\n",
    "    withColumn('SLA_due_date',\n",
    "               date_convert_udf(col('SLA_due_date'))).\n",
    "    withColumn('case_closed',\n",
    "               expr(\"case_closed == 'YES'\")).\n",
    "    withColumn('case_late',\n",
    "               expr(\"case_late == 'YES'\")).\n",
    "    withColumn('num_days_late',\n",
    "               expr(\"num_days_late * -1\").cast('integer')).\n",
    "    withColumn('SLA_days',\n",
    "               col('SLA_days').cast('integer')).\n",
    "    withColumn('case_id',\n",
    "               col('case_id').cast('string'))\n",
    ").drop(col('case_status'))\n",
    "\n",
    "# Create case table alias \n",
    "case_table = case.alias('case_table')\n",
    "\n",
    "# Department csv file datatype conversions\n",
    "dept = (\n",
    "    dept.\n",
    "    withColumn('dept_subject_to_SLA',\n",
    "               expr(\"dept_subject_to_SLA == 'YES'\").cast('boolean'))\n",
    ")\n",
    "\n",
    "# Create dept table alias \n",
    "dept_table = dept.alias('dept_table')\n",
    "\n",
    "# Create source table alias\n",
    "source_table = source.alias('source_table')\n",
    "\n",
    "case.show(1, False, True)\n",
    "dept.show(1, False, True)\n",
    "source.show(1, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9e7703-6207-4c24-a6e6-07c3430ba0eb",
   "metadata": {},
   "source": [
    "### Look at the data to verify what joins need to be performed\n",
    "> * `left_join` on `case` with `dept` on `dept_division` and with `source` on `source_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "794787c9-58c2-4a90-b882-e4ab5fb7af08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------------------------------\n",
      " source_id              | svcCRMLS                             \n",
      " dept_division          | Field Operations                     \n",
      " case_id                | 1014127332                           \n",
      " case_opened_date       | 2018-01-01 00:42:00                  \n",
      " case_closed_date       | 2018-01-01 12:29:00                  \n",
      " SLA_due_date           | 2020-09-26 00:42:00                  \n",
      " case_late              | false                                \n",
      " num_days_late          | 998                                  \n",
      " case_closed            | true                                 \n",
      " service_request_type   | Stray Animal                         \n",
      " SLA_days               | 999                                  \n",
      " request_address        | 2315  EL PASO ST, San Antonio, 78207 \n",
      " council_district       | 5                                    \n",
      " dept_name              | Animal Care Services                 \n",
      " standardized_dept_name | Animal Care Services                 \n",
      " dept_subject_to_SLA    | true                                 \n",
      " source_username        | svcCRMLS                             \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "case = (\n",
    "    case_table.join(   # Join the case & dept on dept_division\n",
    "        dept_table, ['dept_division']).\n",
    "    join(              # Join the case & source on source_id\n",
    "        source_table, ['source_id'])\n",
    ")\n",
    "\n",
    "# Create and replace case as df_table \n",
    "case.createOrReplaceTempView('df_table')\n",
    "\n",
    "case.show(1, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cb1605-0e9f-42c2-98a4-5db88903e06e",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## 1a. How old is the latest (in terms of days past SLA) currently open issue? \n",
    "\n",
    "|    |    case_id | dept_division   |   SLA_oldest_currently_open_issue |\n",
    "|---:|-----------:|:----------------|----------------------------------:|\n",
    "|  0 | 1014128388 | 311 Call Center |                              1419 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b0d2500-7215-4b7c-9def-37eeabcb1b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:>                                                       (0 + 12) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    |    case_id | dept_division   |   SLA_oldest_currently_open_issue |\n",
      "|---:|-----------:|:----------------|----------------------------------:|\n",
      "|  0 | 1014128388 | 311 Call Center |                              1419 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print((\n",
    "    spark.sql(\n",
    "        '''\n",
    "        SELECT \n",
    "        first(case_id) as case_id,\n",
    "        first(dept_division) as dept_division,\n",
    "        (MAX(SLA_days)) as SLA_oldest_currently_open_issue\n",
    "        FROM df_table\n",
    "        WHERE case_closed is False\n",
    "        '''\n",
    "    )).toPandas().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e9d055-9ec9-4130-b8c9-117a18b4db20",
   "metadata": {},
   "source": [
    "## 1b. How long has the oldest (in terms of days since opened) currently opened issue been open?\n",
    "\n",
    "|    case_id | dept_division   |   oldest_currently_open_issue |\n",
    "|-----------:|:----------------|------------------------------:|\n",
    "| 1014128388 | 311 Call Center |                          1387 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66d4310e-e9aa-4611-9dc1-28ef888e37a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    |    case_id | dept_division   |   oldest_currently_open_issue |\n",
      "|---:|-----------:|:----------------|------------------------------:|\n",
      "|  0 | 1014128388 | 311 Call Center |                          1387 |\n"
     ]
    }
   ],
   "source": [
    "print((\n",
    "    spark.sql(\n",
    "        '''\n",
    "        SELECT \n",
    "        first(case_id) as case_id,\n",
    "        first(dept_division) as dept_division,\n",
    "        (MAX(num_days_late)) as oldest_currently_open_issue\n",
    "        FROM df_table\n",
    "        WHERE case_closed is False\n",
    "        '''\n",
    "    )).toPandas().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd19e3d8-bed2-4207-a4a1-bbf68a253412",
   "metadata": {},
   "source": [
    "## 2. How many Stray Animal cases are there?\n",
    "\n",
    "|    | service_request_type   |   count |\n",
    "|---:|:-----------------------|--------:|\n",
    "|  0 | Stray Animal           |   27361 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "933eb908-27f5-43f0-9d3a-3e296740aff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | service_request_type   |   count |\n",
      "|---:|:-----------------------|--------:|\n",
      "|  0 | Stray Animal           |   27361 |\n"
     ]
    }
   ],
   "source": [
    "print((\n",
    "    case.groupBy('service_request_type').count().\n",
    "    filter(case.service_request_type == 'Stray Animal')\n",
    ").toPandas().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ffe902-afa6-4acb-87e4-b0831b5b1056",
   "metadata": {},
   "source": [
    "## 3. How many service requests that are assigned to the Field Operations department (`dept_division`) are not classified as \"Officer Standby\" request type (`service_request_type`)?\n",
    "\n",
    "|    | dept_division    |   count |\n",
    "|---:|:-----------------|--------:|\n",
    "|  0 | Field Operations |  116295 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a818eb09-c1f0-4c5a-9f62-f06b4dcfc70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | dept_division    |   count |\n",
      "|---:|:-----------------|--------:|\n",
      "|  0 | Field Operations |  116295 |\n"
     ]
    }
   ],
   "source": [
    "# First need to filter by the two options, then we can groupby and get counts\n",
    "print((\n",
    "    case.filter(\n",
    "        (case.dept_division == 'Field Operations') \n",
    "        & (case.service_request_type != 'Officer Standby')).\n",
    "    groupBy('dept_division').\n",
    "    count()\n",
    ").toPandas().to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3080924-5f1d-462f-9dfd-a9a48ef75a91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
